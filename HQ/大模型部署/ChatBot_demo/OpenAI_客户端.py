"""
å¤šè½®å¯¹è¯åŸºæœ¬æ€è·¯ï¼š
å®šä¹‰ä¸€ä¸ªæ¶ˆæ¯åˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨å¯¹è¯å†å²ï¼Œé€šè¿‡APIæ¥å£å‘ OpenAIå‘é€è¯·æ±‚ã€‚
æ¯æ¬¡è¯·æ±‚éƒ½åŒ…å«å®Œæ•´çš„å¯¹è¯å†å²ï¼ŒOpenAIä¼šæ ¹æ®ä¸Šä¸‹æ–‡ç”Ÿæˆå›ç­”ã€‚
è¿”å›ç»“æœä¹‹åï¼Œå°†å…¶æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨ä¸­ï¼Œä»¥ä¾¿ç»´æŒä¸Šä¸‹æ–‡ã€‚
"""

from openai import OpenAI

API_KEY = "sk-lolzalmconplprhxshsxunwdhpvlflbdbhneyyuyboqfbtsk"
URL = "https://api.siliconflow.cn/v1"
MODEL_NAME = "Qwen/Qwen2.5-7B-Instruct"

# åˆ›å»ºOpenAIå¯¹è±¡
client = OpenAI(api_key=API_KEY,  base_url=URL)

# åˆå§‹åŒ–æ¶ˆæ¯åˆ—è¡¨
messages = [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªçˆ±ä½¿ç”¨é¢œæ–‡å­—çš„ç§äººåŠ©æ‰‹"}
]

# è°ƒç”¨å¤§æ¨¡å‹çš„å‡½æ•°
def get_response(messages):
    """æŠŠ messages å‘ç»™ model â†’ æ‹¿åˆ°å›å¤"""
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            max_tokens=1024,
            temperature=0.7,
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"Error: {e}")
        return None

# è¿›è¡Œå¤šè½®å¯¹è¯
while True:
    # è·å–ç”¨æˆ·è¾“å…¥
    user_input = input("è¯¢é—®ä»»ä½•é—®é¢˜ï¼š")
    if user_input.lower() == 'exit':
        print("å¯¹è¯ç»“æŸ")
        break

    # å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°æ¶ˆæ¯å†å²
    messages.append({"role": "user", "content": user_input})

    # è·å–æ¨¡å‹å›ç­”
    model_response = get_response(messages)
    if model_response:
        print(f"ğŸ¦‹ï¼š{model_response}")
        # å°†æ¨¡å‹å›ç­”æ·»åŠ åˆ°æ¶ˆæ¯å†å²
        messages.append({"role": "assistant", "content": model_response})
    else:
        print("ç§å¯†é©¬èµ›ï¼Œè¿™ä¸ªé—®é¢˜æš‚æ—¶æ— æ³•å›ç­”")

