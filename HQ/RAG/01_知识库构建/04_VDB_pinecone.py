from dotenv import load_dotenv
import os
load_dotenv('VDB.env')
pinecone_api_key = os.getenv('PINECONE_API_KEY')

from sentence_transformers import SentenceTransformer
from pinecone import Pinecone, ServerlessSpec

# ----------------------------------------
# ğŸ“åˆ›å»ºPineconeæ•°æ®åº“ï¼šåˆ›å»ºå®Œæˆåï¼Œå°†æ•°æ®åº“åˆ›å»ºçš„ä»£ç æ³¨é‡Šæ‰
# ----------------------------------------
# åˆå§‹åŒ–Pineconeæ•°æ®åº“ï¼ˆè¿æ¥åˆ°PineconeæœåŠ¡å™¨ï¼‰
pc = Pinecone(api_key=pinecone_api_key)
# ç´¢å¼•åç§°ï¼ˆæ•°æ®åº“åå­—ï¼‰
index_name = "pinecone-demo"
if not pc.has_index(index_name):  # è‹¥ç´¢å¼•ä¸å­˜åœ¨
    # åˆ›å»ºç´¢å¼•
    pc.create_index(
        name=index_name,
        dimension=1024,
        spec=ServerlessSpec(
            cloud="aws",  # ç´¢å¼•æ‰€åœ¨äº‘ï¼ˆä¸ç”¨ç®¡ï¼Œé»˜è®¤äºšé©¬é€Šï¼‰
            region="us-east-1",  # ç´¢å¼•æ‰€åœ¨åŒºåŸŸï¼ˆä¸ç”¨ç®¡ï¼Œé»˜è®¤ç¾å›½ä¸œéƒ¨1ï¼‰
        ),
        metric="cosine",  # ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•
    )
    print(f"è¿œç¨‹çš„æ•°æ®åº“åˆ›å»ºæˆåŠŸï¼Œåº“åä¸º: {index_name}")


# ----------------------------------------
# ğŸ“æ„å»ºæ•°æ®
# ----------------------------------------
# åŠ è½½Embeddingæ¨¡å‹
embed_model = SentenceTransformer(r'C:\HuggingFace\Qwen3-Embedding-0.6B')

# è®¾ç½®è¾“å…¥æ–‡æœ¬
texts = ["çŒ«çŒ«å–œæ¬¢åƒé±¼", "ç‹—ç‹—å–œæ¬¢åƒè‚‰", "ä»Šå¤©å¤©æ°”ä¸é”™"]

# å‘é‡åŒ–
embeds = embed_model.encode(texts)
# print(embeds.shape)  # (3, 1024)

# åˆ›å»ºæŸ¥è¯¢å‘é‡ï¼šæ³¨æ„ï¼Œå‘é‡åŒ–æ¥æ”¶çš„æ˜¯åˆ—è¡¨
query = embed_model.encode(["çŒ«çŒ«å–œæ¬¢åƒä»€ä¹ˆï¼Ÿ"])

# ----------------------------------------
# ğŸ“å‘ç´¢å¼•æ·»åŠ æ•°æ®ï¼ˆæŸ¥è¯¢æ—¶éœ€æ³¨é‡Šæ‰ï¼‰
# ----------------------------------------
# è·å–æ•°æ®åº“ç´¢å¼•å¯¹è±¡
pc = Pinecone(api_key=pinecone_api_key)
index = pc.Index("pinecone-demo")

# å‘ç´¢å¼•ä¸­æ’å…¥å‘é‡
# index.upsert(
#     vectors=[
#         {"id": "vec1", "values": embeds[0].tolist()},
#         {"id": "vec2", "values": embeds[1].tolist()},
#         {"id": "vec3", "values": embeds[2].tolist()},
#     ]
# )
# åˆ—è¡¨æ¨å¯¼å¼
vectors = [
    {"id": f"vec{i}", "values": embeds[i].tolist()}
    for i in range(len(texts))
]
index.upsert(vectors=vectors)

# ----------------------------------------
# ğŸ“ç›¸ä¼¼åº¦æŸ¥è¯¢
# ----------------------------------------
# è·å–æ•°æ®åº“ç´¢å¼•å¯¹è±¡
pc = Pinecone(api_key=pinecone_api_key)
index = pc.Index("pinecone-demo")

# æŸ¥è¯¢ç›¸ä¼¼å‘é‡
res = index.query(
    vector = query[0].tolist(),  # æŸ¥è¯¢å‘é‡
    top_k=2,  # è¿”å›æœ€ç›¸ä¼¼çš„Kä¸ªå‘é‡
    include_values=False,  # æ˜¯å¦è¿”å›æŸ¥è¯¢çš„å®é™…å‘é‡
)

print(res)
"""
res ï¼šæŸ¥è¯¢ç»“æœï¼Œdictç±»å‹
- matchesï¼šæŸ¥è¯¢ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºä¸€ä¸ªdictï¼ŒåŒ…å«ä»¥ä¸‹é”®å€¼å¯¹ï¼š
    - idï¼šå‘é‡ID
    - scoreï¼šç›¸ä¼¼åº¦å¾—åˆ†
    - valuesï¼šå‘é‡å®é™…å€¼ï¼ˆç©ºåˆ—è¡¨å› ä¸ºinclude_values=Falseï¼‰
- namespaceï¼šå‘½åç©ºé—´ï¼ˆé»˜è®¤ç©ºå­—ç¬¦ä¸²ï¼‰
- usageï¼šæŸ¥è¯¢ä½¿ç”¨æƒ…å†µï¼ŒåµŒå¥—dictï¼š
    - read_unitsï¼šè¯»å–å•ä½æ•°
"""

# ----------------------------------------
# ğŸ“åˆ é™¤å‘é‡æ•°æ®åº“
# ----------------------------------------
pc = Pinecone(api_key=pinecone_api_key)
pc.delete_index("pinecone-demo")